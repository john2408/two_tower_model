{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Tower Model Implementation in PyTorch\n",
    "\n",
    "## Content-based filtering with a Two Tower neural network\n",
    "\n",
    "This notebooks aims to implement the a content-based filtering algorithm for a movie recommendation system using the two tower approach. Based on the implementation of Andrew NG [Link to Tensorflow Implementation](https://github.com/john2408/Machine-Learning-Specialization-Coursera/blob/main/C3%20-%20Unsupervised%20Learning%2C%20Recommenders%2C%20Reinforcement%20Learning/week2/C3W2/C3W2A2/C3_W2_RecSysNN_Assignment.ipynb). However, we aim to leverage the Pytorch landscape, and implement the example using the pytorch lighting library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "from numpy import genfromtxt\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import tabulate\n",
    "import sys, os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from src.movie_dataset_utils import load_data\n",
    "pd.set_option(\"display.precision\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-based filtering with a Two Tower neural network\n",
    "\n",
    "<figure>\n",
    "    <center> <img src=\"./images/RecSysNN.png\"   style=\"width:500px;height:280px;\" ></center>\n",
    "</figure>\n",
    "\n",
    "The Two-Tower model is a neural network architecture used for recommendation systems. It consists of two separate neural networks (towers) that learn user and item representations independently. The user tower processes user features, while the item tower processes item features. The outputs of these towers are then combined, typically using a similarity measure like cosine similarity, to predict the relevance score or rating for a given user-item pair. This model allows for efficient retrieval of recommendations by precomputing item representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Movie ratings dataset \n",
    "The data set is derived from the [MovieLens ml-latest-small](https://grouplens.org/datasets/movielens/latest/) dataset. \n",
    "\n",
    "[F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4: 19:1â€“19:19. <https://doi.org/10.1145/2827872>]\n",
    "\n",
    "The original dataset has 9000 movies rated by 600 users with ratings on a scale of 0.5 to 5 in 0.5 step increments. The dataset has been reduced in size to focus on movies from the years since 2000 and popular genres. The reduced dataset has $n_u = 395$ users and $n_m= 694$ movies. For each movie, the dataset provides a movie title, release date, and one or more genres. For example \"Toy Story 3\" was released in 2010 and has several genres: \"Adventure|Animation|Children|Comedy|Fantasy|IMAX\".  This dataset contains little information about users other than their ratings. This dataset is used to create training vectors for the neural networks described below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "/Users/JOHTORR/Repos/two_tower_model/notebooks/data/gold/movie_dataset/content_item_train.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m cwd \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\n\u001b[1;32m      3\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cwd, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/gold/movie_dataset/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m item_train, user_train, y_train, item_features, user_features, item_vecs, movie_dict, user_to_genre \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m num_user_features \u001b[38;5;241m=\u001b[39m user_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# remove userid, rating count and ave rating during training\u001b[39;00m\n\u001b[1;32m      8\u001b[0m num_item_features \u001b[38;5;241m=\u001b[39m item_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# remove movie id at train time\u001b[39;00m\n",
      "File \u001b[0;32m~/Repos/two_tower_model/src/movie_dataset_utils.py:30\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     27\u001b[0m user_train_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_user_train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m y_train_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_y_train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m item_train \u001b[38;5;241m=\u001b[39m \u001b[43mgenfromtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem_train_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m user_train \u001b[38;5;241m=\u001b[39m genfromtxt(user_train_path, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     32\u001b[0m y_train    \u001b[38;5;241m=\u001b[39m genfromtxt(y_train_path, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Repos/two_tower_model/.venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:1990\u001b[0m, in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, ndmin, like)\u001b[0m\n\u001b[1;32m   1988\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(fname)\n\u001b[1;32m   1989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m-> 1990\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datasource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1991\u001b[0m     fid_ctx \u001b[38;5;241m=\u001b[39m contextlib\u001b[38;5;241m.\u001b[39mclosing(fid)\n\u001b[1;32m   1992\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Repos/two_tower_model/.venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:192\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    191\u001b[0m ds \u001b[38;5;241m=\u001b[39m DataSource(destpath)\n\u001b[0;32m--> 192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/two_tower_model/.venv/lib/python3.12/site-packages/numpy/lib/_datasource.py:529\u001b[0m, in \u001b[0;36mDataSource.open\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    527\u001b[0m                               encoding\u001b[38;5;241m=\u001b[39mencoding, newline\u001b[38;5;241m=\u001b[39mnewline)\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: /Users/JOHTORR/Repos/two_tower_model/notebooks/data/gold/movie_dataset/content_item_train.csv not found."
     ]
    }
   ],
   "source": [
    "# Load Data, set configuration variables\n",
    "cwd = os.getcwd()\n",
    "path = os.path.join(cwd, \"data/gold/movie_dataset/\")\n",
    "item_train, user_train, y_train, item_features, user_features, item_vecs, movie_dict, user_to_genre = load_data(path=path)\n",
    "\n",
    "\n",
    "num_user_features = user_train.shape[1] - 3  # remove userid, rating count and ave rating during training\n",
    "num_item_features = item_train.shape[1] - 1  # remove movie id at train time\n",
    "uvs = 3  # user genre vector start\n",
    "ivs = 3  # item genre vector start\n",
    "u_s = 3  # start of columns to use in training, user\n",
    "i_s = 1  # start of columns to use in training, items\n",
    "scaledata = True  # applies the standard scalar to data if true\n",
    "print(f\"Number of training vectors: {len(item_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58187, 58187, 58187)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_train), len(item_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1883"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(item_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: center;\"> [user id] </th><th style=\"text-align: center;\"> [rating count] </th><th style=\"text-align: center;\"> [rating ave] </th><th style=\"text-align: center;\"> Act ion </th><th style=\"text-align: center;\"> Adve nture </th><th style=\"text-align: center;\"> Anim ation </th><th style=\"text-align: center;\"> Chil dren </th><th style=\"text-align: center;\"> Com edy </th><th style=\"text-align: center;\"> Crime </th><th style=\"text-align: center;\"> Docum entary </th><th style=\"text-align: center;\"> Drama </th><th style=\"text-align: center;\"> Fan tasy </th><th style=\"text-align: center;\"> Hor ror </th><th style=\"text-align: center;\"> Mys tery </th><th style=\"text-align: center;\"> Rom ance </th><th style=\"text-align: center;\"> Sci -Fi </th><th style=\"text-align: center;\"> Thri ller </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\n",
       "<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\n",
       "<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\n",
       "<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\n",
       "<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th style=\"text-align: center;\"> [user id] </th><th style=\"text-align: center;\"> [rating count] </th><th style=\"text-align: center;\"> [rating ave] </th><th style=\"text-align: center;\"> Act ion </th><th style=\"text-align: center;\"> Adve nture </th><th style=\"text-align: center;\"> Anim ation </th><th style=\"text-align: center;\"> Chil dren </th><th style=\"text-align: center;\"> Com edy </th><th style=\"text-align: center;\"> Crime </th><th style=\"text-align: center;\"> Docum entary </th><th style=\"text-align: center;\"> Drama </th><th style=\"text-align: center;\"> Fan tasy </th><th style=\"text-align: center;\"> Hor ror </th><th style=\"text-align: center;\"> Mys tery </th><th style=\"text-align: center;\"> Rom ance </th><th style=\"text-align: center;\"> Sci -Fi </th><th style=\"text-align: center;\"> Thri ller </th></tr>\\n</thead>\\n<tbody>\\n<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\\n<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\\n<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\\n<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\\n<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pprint_train(user_train, user_features, uvs,  u_s, maxcount=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: center;\"> [movie id] </th><th style=\"text-align: center;\"> year </th><th style=\"text-align: center;\"> ave rating </th><th style=\"text-align: center;\"> Act ion </th><th style=\"text-align: center;\"> Adve nture </th><th style=\"text-align: center;\"> Anim ation </th><th style=\"text-align: center;\"> Chil dren </th><th style=\"text-align: center;\"> Com edy </th><th style=\"text-align: center;\"> Crime </th><th style=\"text-align: center;\"> Docum entary </th><th style=\"text-align: center;\"> Drama </th><th style=\"text-align: center;\"> Fan tasy </th><th style=\"text-align: center;\"> Hor ror </th><th style=\"text-align: center;\"> Mys tery </th><th style=\"text-align: center;\"> Rom ance </th><th style=\"text-align: center;\"> Sci -Fi </th><th style=\"text-align: center;\"> Thri ller </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: center;\">    6874    </td><td style=\"text-align: center;\"> 2003 </td><td style=\"text-align: center;\">    4.0     </td><td style=\"text-align: center;\">    1    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\n",
       "<tr><td style=\"text-align: center;\">    6874    </td><td style=\"text-align: center;\"> 2003 </td><td style=\"text-align: center;\">    4.0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\n",
       "<tr><td style=\"text-align: center;\">    6874    </td><td style=\"text-align: center;\"> 2003 </td><td style=\"text-align: center;\">    4.0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     1     </td></tr>\n",
       "<tr><td style=\"text-align: center;\">    8798    </td><td style=\"text-align: center;\"> 2004 </td><td style=\"text-align: center;\">    3.8     </td><td style=\"text-align: center;\">    1    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\n",
       "<tr><td style=\"text-align: center;\">    8798    </td><td style=\"text-align: center;\"> 2004 </td><td style=\"text-align: center;\">    3.8     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th style=\"text-align: center;\"> [movie id] </th><th style=\"text-align: center;\"> year </th><th style=\"text-align: center;\"> ave rating </th><th style=\"text-align: center;\"> Act ion </th><th style=\"text-align: center;\"> Adve nture </th><th style=\"text-align: center;\"> Anim ation </th><th style=\"text-align: center;\"> Chil dren </th><th style=\"text-align: center;\"> Com edy </th><th style=\"text-align: center;\"> Crime </th><th style=\"text-align: center;\"> Docum entary </th><th style=\"text-align: center;\"> Drama </th><th style=\"text-align: center;\"> Fan tasy </th><th style=\"text-align: center;\"> Hor ror </th><th style=\"text-align: center;\"> Mys tery </th><th style=\"text-align: center;\"> Rom ance </th><th style=\"text-align: center;\"> Sci -Fi </th><th style=\"text-align: center;\"> Thri ller </th></tr>\\n</thead>\\n<tbody>\\n<tr><td style=\"text-align: center;\">    6874    </td><td style=\"text-align: center;\"> 2003 </td><td style=\"text-align: center;\">    4.0     </td><td style=\"text-align: center;\">    1    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\\n<tr><td style=\"text-align: center;\">    6874    </td><td style=\"text-align: center;\"> 2003 </td><td style=\"text-align: center;\">    4.0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\\n<tr><td style=\"text-align: center;\">    6874    </td><td style=\"text-align: center;\"> 2003 </td><td style=\"text-align: center;\">    4.0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     1     </td></tr>\\n<tr><td style=\"text-align: center;\">    8798    </td><td style=\"text-align: center;\"> 2004 </td><td style=\"text-align: center;\">    3.8     </td><td style=\"text-align: center;\">    1    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\\n<tr><td style=\"text-align: center;\">    8798    </td><td style=\"text-align: center;\"> 2004 </td><td style=\"text-align: center;\">    3.8     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pprint_train(item_train, item_features, ivs, i_s, maxcount=5, user=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Tower Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "from einops import rearrange\n",
    "\n",
    "\n",
    "# class CrossMultiHeadAttention(MultiHeadAttention):\n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         \"\"\"\n",
    "#         See MultiHeadAttention.\n",
    "#         Takes a cross hidden as query. Needs to be same dimension!\n",
    "#         \"\"\"\n",
    "#         super().__init__(*args, **kwargs)\n",
    "\n",
    "#         self.to_qkv = torch.nn.Linear(self.dim_input, self.dim_head * self.nr_heads * 2, bias=False)\n",
    "#         self.to_q = torch.nn.Linear(self.dim_input, self.dim_head * self.nr_heads, bias=False)\n",
    "\n",
    "#     def forward(self, x: torch.Tensor, cross_hidden: torch.Tensor, attn_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "#         assert cross_hidden.shape[-1] == x.shape[-1], \"Input and cross input require same embedding dimension!\"\n",
    "\n",
    "#         h = self.nr_heads\n",
    "#         k, v = self.to_qkv(x).chunk(2, dim=-1)\n",
    "#         q = self.to_q(cross_hidden)\n",
    "#         q, k, v = map(lambda t: rearrange(t, \"b n (h d) -> b h n d\", h=h), (q, k, v))\n",
    "#         sim = torch.einsum(\"b h i d, b h j d -> b h i j\", q, k) * self.scale\n",
    "\n",
    "#         if attn_mask is not None:\n",
    "#             attn_mask = attn_mask.unsqueeze(1)  # Add an extra dimension for the heads (b, 1, i, j)\n",
    "#             sim = sim.masked_fill(attn_mask == 0, float(\"-inf\"))\n",
    "\n",
    "#         attn = sim.softmax(dim=-1)\n",
    "#         attn = self.dropout(attn)\n",
    "\n",
    "#         out = torch.einsum(\"b h i j, b h j d -> b h i d\", attn, v)\n",
    "#         out = rearrange(out, \"b h n d -> b n (h d)\", h=h)\n",
    "        \n",
    "#         return self.to_out(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_input: int,\n",
    "        nr_heads: int = 8,\n",
    "        dropout_p: float = 0.0,\n",
    "        scale_factor: float = 0.5,\n",
    "    ):\n",
    "        \"\"\"Ye olde Multihead Attention, implmented with Einstein Notation.\n",
    "        Note: There' ain't no masking here, so be careful!\n",
    "\n",
    "        Args:\n",
    "            dim_input (int): The input dimension\n",
    "            nr_heads (int, optional): Number of heads. Defaults to 8.\n",
    "            dropout_p (float, optional): Dropout. Defaults to 0.0.\n",
    "            scale_factor (float, optional): Exponent of the scaling division - default is square root. Defaults to 0.5.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.nr_heads = nr_heads\n",
    "        self.dim_input = dim_input\n",
    "        self.dim_head = dim_input // nr_heads\n",
    "        self.scale = self.dim_head**-scale_factor\n",
    "\n",
    "        self.to_qkv = torch.nn.Linear(dim_input, self.dim_head * self.nr_heads * 3, bias=False)\n",
    "\n",
    "        self.to_out = torch.nn.Linear(self.dim_head * nr_heads, dim_input)\n",
    "        self.dropout = torch.nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, attn_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        h = self.nr_heads\n",
    "        q, k, v = self.to_qkv(x).chunk(3, dim=-1)\n",
    "        q, k, v = map(lambda t: rearrange(t, \"b n (h d) -> b h n d\", h=h), (q, k, v))\n",
    "        sim = torch.einsum(\"b h i d, b h j d -> b h i j\", q, k) * self.scale\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            attn_mask = attn_mask.unsqueeze(1)  # Add an extra dimension for the heads (b, 1, i, j)\n",
    "            sim = sim.masked_fill(attn_mask == 0, float(\"-inf\"))\n",
    "\n",
    "        attn = sim.softmax(dim=-1)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = torch.einsum(\"b h i j, b h j d -> b h i d\", attn, v)\n",
    "        out = rearrange(out, \"b h n d -> b n (h d)\", h=h)\n",
    "        return self.to_out(out)\n",
    "\n",
    "\n",
    "class UserTower(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, output_dim, nr_heads):\n",
    "        super(UserTower, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        # Input Embedding Layer (projects 4D input to embed_dim)\n",
    "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
    "        # Multi-Head Attention Layer\n",
    "        self.attention = MultiHeadAttention(dim_input=embed_dim, nr_heads=nr_heads)\n",
    "        # Fully Connected Layer (maps back to scalar output)\n",
    "        self.fc = nn.Linear(embed_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        x = self.embedding(x)  # Project to higher dimension\n",
    "        x = x.unsqueeze(1)  # Add sequence dimension: (batch, seq_len=1, embed_dim)\n",
    "        attn_output = self.attention(x, x)   \n",
    "        x = attn_output.mean(dim=1)  # Average over sequence dimension\n",
    "        return self.fc(x) \n",
    "\n",
    "class ProductTower(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, output_dim, nr_heads):\n",
    "        super(ProductTower, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        # Input Embedding Layer (projects 4D input to embed_dim)\n",
    "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
    "        # Multi-Head Attention Layer\n",
    "        self.attention = MultiHeadAttention(dim_input=embed_dim, nr_heads=nr_heads)\n",
    "        # Fully Connected Layer (maps back to scalar output)\n",
    "        self.fc = nn.Linear(embed_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        x = self.embedding(x)  # Project to higher dimension\n",
    "        x = x.unsqueeze(1)  # Add sequence dimension: (batch, seq_len=1, embed_dim)\n",
    "        attn_output = self.attention(x, x)   \n",
    "        x = attn_output.mean(dim=1)  # Average over sequence dimension\n",
    "        return self.fc(x) \n",
    "\n",
    "\n",
    "class UserTower(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, output_dim, nr_heads, window_size=3):\n",
    "        super(UserTower, self).__init__()\n",
    "        self.window_size = window_size  # Window size for rolling\n",
    "        # Input Embedding Layer (projects 4D input to embed_dim)\n",
    "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
    "        # Multi-Head Attention Layer\n",
    "        self.attention = MultiHeadAttention(dim_input=embed_dim, nr_heads=nr_heads)\n",
    "        # Fully Connected Layer (maps back to scalar output)\n",
    "        self.fc = nn.Linear(embed_dim, output_dim)\n",
    "\n",
    "    def rolling_window(self, x, window_size):\n",
    "        \"\"\"\n",
    "        Creates overlapping sequences using a rolling window approach.\n",
    "        \"\"\"\n",
    "        batch_size, embed_dim = x.shape\n",
    "        if embed_dim < window_size:\n",
    "            raise ValueError(\"Embed_dim should be greater than or equal to window_size\")\n",
    "\n",
    "        return x.unfold(dimension=1, size=window_size, step=1)  # (batch_size, embed_dim-window_size+1, window_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.embedding(x))  # Apply first linear layer with activation\n",
    "        x = self.rolling_window(x, self.window_size)  # Create overlapping sequences\n",
    "        # Multihead Attention expects (batch_size, seq_len, hidden_dim) -> (seq_len, batch_size, hidden_dim)\n",
    "        x = x.permute(0, 2, 1)  \n",
    "        attn_output = self.attention(x, x)   \n",
    "        x = attn_output.permute(1, 0, 2)  # Convert back to (batch, seq_len, hidden_dim)\n",
    "        x = self.output_layer(x.mean(dim=1))  # Pooling + Final Linear Layer\n",
    "        return x\n",
    "    \n",
    "class UserTower_MLP(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, output_dim, nr_heads):\n",
    "        super(UserTower_MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, embed_dim)\n",
    "        self.fc2 = nn.Linear(embed_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "class ProductTower_MLP(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, output_dim):\n",
    "        super(ProductTower_MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, embed_dim)\n",
    "        self.fc2 = nn.Linear(embed_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "class TwoTowerRecommendationModel(pl.LightningModule):\n",
    "    def __init__(self, user_config, product_config, learning_rate):\n",
    "        super(TwoTowerRecommendationModel, self).__init__()\n",
    "        self.user_tower = UserTower(**user_config)\n",
    "        self.product_tower = ProductTower(**product_config)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, user_input, product_input):\n",
    "        \n",
    "        product_output = self.product_tower(product_input)\n",
    "        user_output = self.user_tower(user_input)\n",
    "        rating_pred_tensor = F.cosine_similarity(user_output, product_output)\n",
    "        return rating_pred_tensor\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        user_input, product_input, target = batch\n",
    "        rating_pred_tensor = self(user_input, product_input)\n",
    "        loss = self.criterion(rating_pred_tensor, target)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        user_input, product_input, target = batch\n",
    "        rating_pred_tensor = self(user_input, product_input)\n",
    "        loss = self.criterion(rating_pred_tensor, target)\n",
    "        self.log('val_loss', loss)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        user_input, product_input, target = batch\n",
    "        rating_pred_tensor = self(user_input, product_input)\n",
    "        loss = self.criterion(rating_pred_tensor, target)\n",
    "        self.log('test_loss', loss)\n",
    "        return {'preds': rating_pred_tensor, 'target': target}\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        user_input, product_input, _ = batch\n",
    "        rating_pred_tensor = self(user_input, product_input)\n",
    "        return rating_pred_tensor\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "# Generate Random Sample Data\n",
    "def generate_random_sample_data(num_samples: int):\n",
    "    \"\"\"This function generates random sample data for the two-tower model.\n",
    "    The idea is to understand how to structure the data for the model.\n",
    "\n",
    "    Args:\n",
    "        num_samples (int): number of samples\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    user_input_dim = 6\n",
    "    product_input_dim = 3\n",
    "    user_data = np.random.rand(num_samples, user_input_dim)\n",
    "    product_data = np.random.rand(num_samples, product_input_dim)\n",
    "    target_data = np.random.randint(0, 2, size=(num_samples, 1))  # Binary targets for F1 score\n",
    "\n",
    "    user_tensor = torch.tensor(user_data, dtype=torch.float32)\n",
    "    product_tensor = torch.tensor(product_data, dtype=torch.float32)\n",
    "    target_tensor = torch.tensor(target_data, dtype=torch.float32)\n",
    "\n",
    "    return user_tensor, product_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_synthetic_data = False\n",
    "if use_synthetic_data:\n",
    "    # Generate synthetic data\n",
    "    num_samples = 1000\n",
    "    user_data, product_data, target_data = generate_random_sample_data(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the shape of the data from movie lens dataset\n",
    "#user_data.shape, product_data.shape, target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# scale training data\n",
    "scaledata = True\n",
    "if scaledata:\n",
    "    item_train_save = item_train\n",
    "    user_train_save = user_train\n",
    "    y_train_save = y_train\n",
    "\n",
    "    scalerItem = StandardScaler()\n",
    "    scalerItem.fit(item_train)\n",
    "    item_train = scalerItem.transform(item_train)\n",
    "\n",
    "    scalerUser = StandardScaler()\n",
    "    scalerUser.fit(user_train)\n",
    "    user_train = scalerUser.transform(user_train)\n",
    "    \n",
    "    targetScaler = MinMaxScaler((-1, 1))\n",
    "    targetScaler.fit(y_train.reshape(-1, 1))\n",
    "    y_train = targetScaler.transform(y_train.reshape(-1, 1))\n",
    "\n",
    "    print(np.allclose(item_train_save, scalerItem.inverse_transform(item_train)))\n",
    "    print(np.allclose(user_train_save, scalerUser.inverse_transform(user_train)))\n",
    "\n",
    "user_data_tensor = torch.tensor(user_train[:, u_s:], dtype=torch.float32)\n",
    "product_data_tensor = torch.tensor(item_train[:, i_s:], dtype=torch.float32)\n",
    "target_data_tensor = torch.tensor(y_train.reshape(-1,1), dtype=torch.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.), tensor(-1.))"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data_tensor.max(), target_data_tensor.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([58187, 14]), torch.Size([58187, 16]), torch.Size([58187, 1]))"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data_tensor.shape, product_data_tensor.shape, target_data_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([58187, 14])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type         | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | user_tower    | UserTower    | 75.8 K | train\n",
      "1 | product_tower | ProductTower | 76.1 K | train\n",
      "2 | criterion     | MSELoss      | 0      | train\n",
      "-------------------------------------------------------\n",
      "151 K     Trainable params\n",
      "0         Non-trainable params\n",
      "151 K     Total params\n",
      "0.608     Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JOHTORR/Repos/two_tower_model/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=13` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "linear(): input and weight.T shapes cannot be multiplied (3x126 and 128x384)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[298], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Train the model on GPU\u001b[39;00m\n\u001b[1;32m     41\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39mepochs, accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/two_tower_model/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:539\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 539\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/two_tower_model/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     50\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/Repos/two_tower_model/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:575\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    569\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    571\u001b[0m     ckpt_path,\n\u001b[1;32m    572\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    574\u001b[0m )\n\u001b[0;32m--> 575\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Repos/two_tower_model/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:982\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 982\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    987\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Repos/two_tower_model/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1024\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1024\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1026\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/Repos/two_tower_model/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1053\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1050\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1053\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/Repos/two_tower_model/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py:179\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/two_tower_model/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py:144\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Repos/two_tower_model/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py:433\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    427\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    428\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    432\u001b[0m )\n\u001b[0;32m--> 433\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/Repos/two_tower_model/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:323\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 323\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    326\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/Repos/two_tower_model/.venv/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py:412\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[291], line 161\u001b[0m, in \u001b[0;36mTwoTowerRecommendationModel.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[1;32m    160\u001b[0m     user_input, product_input, target \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m--> 161\u001b[0m     rating_pred_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproduct_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(rating_pred_tensor, target)\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, loss)\n",
      "File \u001b[0;32m~/Repos/two_tower_model/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/two_tower_model/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[291], line 148\u001b[0m, in \u001b[0;36mTwoTowerRecommendationModel.forward\u001b[0;34m(self, user_input, product_input)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, user_input, product_input):\n\u001b[1;32m    147\u001b[0m     product_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproduct_tower(product_input)\n\u001b[0;32m--> 148\u001b[0m     user_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_tower\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m     rating_pred_tensor \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcosine_similarity(user_output, product_output)\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rating_pred_tensor\n",
      "File \u001b[0;32m~/Repos/two_tower_model/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/two_tower_model/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[291], line 110\u001b[0m, in \u001b[0;36mUserTower.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Multihead Attention expects (batch_size, seq_len, hidden_dim) -> (seq_len, batch_size, hidden_dim)\u001b[39;00m\n\u001b[1;32m    109\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \n\u001b[0;32m--> 110\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m   \n\u001b[1;32m    111\u001b[0m x \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Convert back to (batch, seq_len, hidden_dim)\u001b[39;00m\n\u001b[1;32m    112\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(x\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Pooling + Final Linear Layer\u001b[39;00m\n",
      "File \u001b[0;32m~/Repos/two_tower_model/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/two_tower_model/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[291], line 31\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, x, attn_mask)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, attn_mask: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     30\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnr_heads\n\u001b[0;32m---> 31\u001b[0m     q, k, v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_qkv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m3\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     32\u001b[0m     q, k, v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m t: rearrange(t, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb n (h d) -> b h n d\u001b[39m\u001b[38;5;124m\"\u001b[39m, h\u001b[38;5;241m=\u001b[39mh), (q, k, v))\n\u001b[1;32m     33\u001b[0m     sim \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb h i d, b h j d -> b h i j\u001b[39m\u001b[38;5;124m\"\u001b[39m, q, k) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale\n",
      "File \u001b[0;32m~/Repos/two_tower_model/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/two_tower_model/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Repos/two_tower_model/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: linear(): input and weight.T shapes cannot be multiplied (3x126 and 128x384)"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "learning_rate = 0.001\n",
    "use_gpu = True\n",
    "\n",
    "# Model configurations\n",
    "user_config = {'input_dim': user_data_tensor.shape[1], \n",
    "               'embed_dim': 128,\n",
    "               'output_dim': 64, \n",
    "               'nr_heads': 8}\n",
    "product_config = {'input_dim': product_data_tensor.shape[1], \n",
    "                  'embed_dim': 128, \n",
    "                  'output_dim': 64,\n",
    "                  'nr_heads': 8}\n",
    "\n",
    "# Create DataLoader\n",
    "dataset = TensorDataset(user_data_tensor, product_data_tensor, target_data_tensor)\n",
    "num_samples = target_data_tensor.shape[0]\n",
    "train_size = int(0.8 * num_samples)\n",
    "test_size = num_samples - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Initialize model\n",
    "model = TwoTowerRecommendationModel(user_config, product_config, learning_rate)\n",
    "\n",
    "if not use_gpu:\n",
    "\n",
    "    # Train the model\n",
    "    trainer = pl.Trainer(max_epochs=epochs)\n",
    "    trainer.fit(model, train_loader, test_loader)\n",
    "\n",
    "else:\n",
    "    # Move model to GPU if available\n",
    "    device = torch.device('mps' if torch.cuda.is_available() else 'mps')\n",
    "    model.to(device)\n",
    "\n",
    "    # Train the model on GPU\n",
    "    trainer = pl.Trainer(max_epochs=epochs, accelerator=\"gpu\", devices=1)\n",
    "    trainer.fit(model, train_loader, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions for a new user\n",
    "First, we'll create a new user and have the model suggest movies for that user. After you have tried this example on the example user content, feel free to change the user content to match your own preferences and see what the model suggests. Note that ratings are between 0.5 and 5.0, inclusive, in half-step increments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_id = 5000\n",
    "new_rating_ave = 1.0\n",
    "new_action = 1.0\n",
    "new_adventure = 1\n",
    "new_animation = 1\n",
    "new_childrens = 1\n",
    "new_comedy = 5\n",
    "new_crime = 1\n",
    "new_documentary = 1\n",
    "new_drama = 1\n",
    "new_fantasy = 1\n",
    "new_horror = 1\n",
    "new_mystery = 1\n",
    "new_romance = 5\n",
    "new_scifi = 5\n",
    "new_thriller = 1\n",
    "new_rating_count = 3\n",
    "\n",
    "user_vec = np.array([[new_user_id, new_rating_count, new_rating_ave,\n",
    "                      new_action, new_adventure, new_animation, new_childrens,\n",
    "                      new_comedy, new_crime, new_documentary,\n",
    "                      new_drama, new_fantasy, new_horror, new_mystery,\n",
    "                      new_romance, new_scifi, new_thriller]])\n",
    "\n",
    "user_vecs = gen_user_vecs(user_vec,len(item_vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1883, 17), (1883, 17))"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_vecs.shape, item_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scaledata:\n",
    "    scaled_user_vecs = scalerUser.transform(user_vecs)\n",
    "    scaled_item_vecs = scalerItem.transform(item_vecs)\n",
    "    user_data_tensor = torch.tensor(scaled_user_vecs[:, u_s:], dtype=torch.float32)\n",
    "    product_data_tensor = torch.tensor(scaled_item_vecs[:, i_s:], dtype=torch.float32)\n",
    "    y_p = model(user_data_tensor, product_data_tensor).detach().numpy()\n",
    "    y_p = targetScaler.inverse_transform(y_p.reshape(-1, 1))\n",
    "else:\n",
    "    y_p = model(user_vecs[:, u_s:], item_vecs[:, i_s:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Vector Shape (1883, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction Vector Shape\", y_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.any(y_p < 0) : \n",
    "    print(\"Error, expected all positive predictions\")\n",
    "sorted_index = np.argsort(-y_p,axis=0).reshape(-1).tolist()  #negate to get largest rating first\n",
    "sorted_ypu   = y_p[sorted_index]\n",
    "sorted_items = item_vecs[sorted_index]\n",
    "sorted_user  = user_vecs[sorted_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p, user, item, movie_dict = sorted_ypu, sorted_user, sorted_items, movie_dict\n",
    "\n",
    "maxcount=10\n",
    "count = 0\n",
    "movies_listed = defaultdict(int)\n",
    "disp = [[\"y_p\", \"movie id\", \"rating ave\", \"title\", \"genres\"]]\n",
    "\n",
    "for i in range(0, y_p.shape[0]):\n",
    "    if count == maxcount:\n",
    "        break\n",
    "    count += 1\n",
    "    movie_id = item[i, 0].astype(int)\n",
    "    if movie_id in movies_listed:\n",
    "        continue\n",
    "    movies_listed[movie_id] = 1\n",
    "    disp.append([y_p[i, 0], item[i, 0].astype(int), item[i, 2].astype(float),\n",
    "                movie_dict[movie_id]['title'], movie_dict[movie_id]['genres']])\n",
    "\n",
    "table = tabulate.tabulate(disp, tablefmt='html',headers=\"firstrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">     y_p</th><th style=\"text-align: right;\">  movie id</th><th style=\"text-align: right;\">  rating ave</th><th>title                                                                      </th><th>genres                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">0.393598</td><td style=\"text-align: right;\">     43928</td><td style=\"text-align: right;\">     1.92308</td><td>Ultraviolet (2006)                                                         </td><td>Action|Fantasy|Sci-Fi|Thriller</td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.393595</td><td style=\"text-align: right;\">     31221</td><td style=\"text-align: right;\">     2.05   </td><td>Elektra (2005)                                                             </td><td>Action|Adventure|Crime|Drama  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.393595</td><td style=\"text-align: right;\">      6482</td><td style=\"text-align: right;\">     1.95455</td><td>Dumb and Dumberer: When Harry Met Lloyd (2003)                             </td><td>Comedy                        </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.393595</td><td style=\"text-align: right;\">     34520</td><td style=\"text-align: right;\">     2.08333</td><td>Dukes of Hazzard, The (2005)                                               </td><td>Action|Adventure|Comedy       </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.393595</td><td style=\"text-align: right;\">      4228</td><td style=\"text-align: right;\">     2.15   </td><td>Heartbreakers (2001)                                                       </td><td>Comedy|Crime|Romance          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.393595</td><td style=\"text-align: right;\">     46335</td><td style=\"text-align: right;\">     2.09091</td><td>Fast and the Furious: Tokyo Drift, The (Fast and the Furious 3, The) (2006)</td><td>Action|Crime|Drama|Thriller   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.393593</td><td style=\"text-align: right;\">     37380</td><td style=\"text-align: right;\">     2.15   </td><td>Doom (2005)                                                                </td><td>Action|Horror|Sci-Fi          </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th style=\"text-align: right;\">     y_p</th><th style=\"text-align: right;\">  movie id</th><th style=\"text-align: right;\">  rating ave</th><th>title                                                                      </th><th>genres                        </th></tr>\\n</thead>\\n<tbody>\\n<tr><td style=\"text-align: right;\">0.393598</td><td style=\"text-align: right;\">     43928</td><td style=\"text-align: right;\">     1.92308</td><td>Ultraviolet (2006)                                                         </td><td>Action|Fantasy|Sci-Fi|Thriller</td></tr>\\n<tr><td style=\"text-align: right;\">0.393595</td><td style=\"text-align: right;\">     31221</td><td style=\"text-align: right;\">     2.05   </td><td>Elektra (2005)                                                             </td><td>Action|Adventure|Crime|Drama  </td></tr>\\n<tr><td style=\"text-align: right;\">0.393595</td><td style=\"text-align: right;\">      6482</td><td style=\"text-align: right;\">     1.95455</td><td>Dumb and Dumberer: When Harry Met Lloyd (2003)                             </td><td>Comedy                        </td></tr>\\n<tr><td style=\"text-align: right;\">0.393595</td><td style=\"text-align: right;\">     34520</td><td style=\"text-align: right;\">     2.08333</td><td>Dukes of Hazzard, The (2005)                                               </td><td>Action|Adventure|Comedy       </td></tr>\\n<tr><td style=\"text-align: right;\">0.393595</td><td style=\"text-align: right;\">      4228</td><td style=\"text-align: right;\">     2.15   </td><td>Heartbreakers (2001)                                                       </td><td>Comedy|Crime|Romance          </td></tr>\\n<tr><td style=\"text-align: right;\">0.393595</td><td style=\"text-align: right;\">     46335</td><td style=\"text-align: right;\">     2.09091</td><td>Fast and the Furious: Tokyo Drift, The (Fast and the Furious 3, The) (2006)</td><td>Action|Crime|Drama|Thriller   </td></tr>\\n<tr><td style=\"text-align: right;\">0.393593</td><td style=\"text-align: right;\">     37380</td><td style=\"text-align: right;\">     2.15   </td><td>Doom (2005)                                                                </td><td>Action|Horror|Sci-Fi          </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
