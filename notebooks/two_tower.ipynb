{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Tower Model Implementation in PyTorch\n",
    "\n",
    "## Content-based filtering with a Two Tower neural network\n",
    "\n",
    "This notebooks aims to implement the a content-based filtering algorithm for a movie recommendation system using the two tower approach. Based on the implementation of Andrew NG [Link to Tensorflow Implementation](https://github.com/john2408/Machine-Learning-Specialization-Coursera/blob/main/C3%20-%20Unsupervised%20Learning%2C%20Recommenders%2C%20Reinforcement%20Learning/week2/C3W2/C3W2A2/C3_W2_RecSysNN_Assignment.ipynb). However, we aim to leverage the Pytorch landscape, and implement the example using the pytorch lighting library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "from numpy import genfromtxt\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import tabulate\n",
    "from recsysNN_utils import *\n",
    "pd.set_option(\"display.precision\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-based filtering with a Two Tower neural network\n",
    "\n",
    "<figure>\n",
    "    <center> <img src=\"./images/RecSysNN.png\"   style=\"width:500px;height:280px;\" ></center>\n",
    "</figure>\n",
    "\n",
    "The Two-Tower model is a neural network architecture used for recommendation systems. It consists of two separate neural networks (towers) that learn user and item representations independently. The user tower processes user features, while the item tower processes item features. The outputs of these towers are then combined, typically using a similarity measure like cosine similarity, to predict the relevance score or rating for a given user-item pair. This model allows for efficient retrieval of recommendations by precomputing item representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Movie ratings dataset \n",
    "The data set is derived from the [MovieLens ml-latest-small](https://grouplens.org/datasets/movielens/latest/) dataset. \n",
    "\n",
    "[F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4: 19:1–19:19. <https://doi.org/10.1145/2827872>]\n",
    "\n",
    "The original dataset has 9000 movies rated by 600 users with ratings on a scale of 0.5 to 5 in 0.5 step increments. The dataset has been reduced in size to focus on movies from the years since 2000 and popular genres. The reduced dataset has $n_u = 395$ users and $n_m= 694$ movies. For each movie, the dataset provides a movie title, release date, and one or more genres. For example \"Toy Story 3\" was released in 2010 and has several genres: \"Adventure|Animation|Children|Comedy|Fantasy|IMAX\".  This dataset contains little information about users other than their ratings. This dataset is used to create training vectors for the neural networks described below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training vectors: 58187\n"
     ]
    }
   ],
   "source": [
    "# Load Data, set configuration variables\n",
    "item_train, user_train, y_train, item_features, user_features, item_vecs, movie_dict, user_to_genre = load_data()\n",
    "\n",
    "num_user_features = user_train.shape[1] - 3  # remove userid, rating count and ave rating during training\n",
    "num_item_features = item_train.shape[1] - 1  # remove movie id at train time\n",
    "uvs = 3  # user genre vector start\n",
    "ivs = 3  # item genre vector start\n",
    "u_s = 3  # start of columns to use in training, user\n",
    "i_s = 1  # start of columns to use in training, items\n",
    "scaledata = True  # applies the standard scalar to data if true\n",
    "print(f\"Number of training vectors: {len(item_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58187, 58187, 58187)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_train), len(item_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1883"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(item_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: center;\"> [user id] </th><th style=\"text-align: center;\"> [rating count] </th><th style=\"text-align: center;\"> [rating ave] </th><th style=\"text-align: center;\"> Act ion </th><th style=\"text-align: center;\"> Adve nture </th><th style=\"text-align: center;\"> Anim ation </th><th style=\"text-align: center;\"> Chil dren </th><th style=\"text-align: center;\"> Com edy </th><th style=\"text-align: center;\"> Crime </th><th style=\"text-align: center;\"> Docum entary </th><th style=\"text-align: center;\"> Drama </th><th style=\"text-align: center;\"> Fan tasy </th><th style=\"text-align: center;\"> Hor ror </th><th style=\"text-align: center;\"> Mys tery </th><th style=\"text-align: center;\"> Rom ance </th><th style=\"text-align: center;\"> Sci -Fi </th><th style=\"text-align: center;\"> Thri ller </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\n",
       "<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\n",
       "<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\n",
       "<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\n",
       "<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th style=\"text-align: center;\"> [user id] </th><th style=\"text-align: center;\"> [rating count] </th><th style=\"text-align: center;\"> [rating ave] </th><th style=\"text-align: center;\"> Act ion </th><th style=\"text-align: center;\"> Adve nture </th><th style=\"text-align: center;\"> Anim ation </th><th style=\"text-align: center;\"> Chil dren </th><th style=\"text-align: center;\"> Com edy </th><th style=\"text-align: center;\"> Crime </th><th style=\"text-align: center;\"> Docum entary </th><th style=\"text-align: center;\"> Drama </th><th style=\"text-align: center;\"> Fan tasy </th><th style=\"text-align: center;\"> Hor ror </th><th style=\"text-align: center;\"> Mys tery </th><th style=\"text-align: center;\"> Rom ance </th><th style=\"text-align: center;\"> Sci -Fi </th><th style=\"text-align: center;\"> Thri ller </th></tr>\\n</thead>\\n<tbody>\\n<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\\n<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\\n<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\\n<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\\n<tr><td style=\"text-align: center;\">     2     </td><td style=\"text-align: center;\">       16       </td><td style=\"text-align: center;\">     4.1      </td><td style=\"text-align: center;\">   3.9   </td><td style=\"text-align: center;\">    5.0     </td><td style=\"text-align: center;\">    0.0     </td><td style=\"text-align: center;\">    0.0    </td><td style=\"text-align: center;\">   4.0   </td><td style=\"text-align: center;\">  4.2  </td><td style=\"text-align: center;\">     4.0      </td><td style=\"text-align: center;\">  4.0  </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   3.0   </td><td style=\"text-align: center;\">   4.0    </td><td style=\"text-align: center;\">   0.0    </td><td style=\"text-align: center;\">   4.2   </td><td style=\"text-align: center;\">    3.9    </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pprint_train(user_train, user_features, uvs,  u_s, maxcount=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: center;\"> [movie id] </th><th style=\"text-align: center;\"> year </th><th style=\"text-align: center;\"> ave rating </th><th style=\"text-align: center;\"> Act ion </th><th style=\"text-align: center;\"> Adve nture </th><th style=\"text-align: center;\"> Anim ation </th><th style=\"text-align: center;\"> Chil dren </th><th style=\"text-align: center;\"> Com edy </th><th style=\"text-align: center;\"> Crime </th><th style=\"text-align: center;\"> Docum entary </th><th style=\"text-align: center;\"> Drama </th><th style=\"text-align: center;\"> Fan tasy </th><th style=\"text-align: center;\"> Hor ror </th><th style=\"text-align: center;\"> Mys tery </th><th style=\"text-align: center;\"> Rom ance </th><th style=\"text-align: center;\"> Sci -Fi </th><th style=\"text-align: center;\"> Thri ller </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: center;\">    6874    </td><td style=\"text-align: center;\"> 2003 </td><td style=\"text-align: center;\">    4.0     </td><td style=\"text-align: center;\">    1    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\n",
       "<tr><td style=\"text-align: center;\">    6874    </td><td style=\"text-align: center;\"> 2003 </td><td style=\"text-align: center;\">    4.0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\n",
       "<tr><td style=\"text-align: center;\">    6874    </td><td style=\"text-align: center;\"> 2003 </td><td style=\"text-align: center;\">    4.0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     1     </td></tr>\n",
       "<tr><td style=\"text-align: center;\">    8798    </td><td style=\"text-align: center;\"> 2004 </td><td style=\"text-align: center;\">    3.8     </td><td style=\"text-align: center;\">    1    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\n",
       "<tr><td style=\"text-align: center;\">    8798    </td><td style=\"text-align: center;\"> 2004 </td><td style=\"text-align: center;\">    3.8     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th style=\"text-align: center;\"> [movie id] </th><th style=\"text-align: center;\"> year </th><th style=\"text-align: center;\"> ave rating </th><th style=\"text-align: center;\"> Act ion </th><th style=\"text-align: center;\"> Adve nture </th><th style=\"text-align: center;\"> Anim ation </th><th style=\"text-align: center;\"> Chil dren </th><th style=\"text-align: center;\"> Com edy </th><th style=\"text-align: center;\"> Crime </th><th style=\"text-align: center;\"> Docum entary </th><th style=\"text-align: center;\"> Drama </th><th style=\"text-align: center;\"> Fan tasy </th><th style=\"text-align: center;\"> Hor ror </th><th style=\"text-align: center;\"> Mys tery </th><th style=\"text-align: center;\"> Rom ance </th><th style=\"text-align: center;\"> Sci -Fi </th><th style=\"text-align: center;\"> Thri ller </th></tr>\\n</thead>\\n<tbody>\\n<tr><td style=\"text-align: center;\">    6874    </td><td style=\"text-align: center;\"> 2003 </td><td style=\"text-align: center;\">    4.0     </td><td style=\"text-align: center;\">    1    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\\n<tr><td style=\"text-align: center;\">    6874    </td><td style=\"text-align: center;\"> 2003 </td><td style=\"text-align: center;\">    4.0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\\n<tr><td style=\"text-align: center;\">    6874    </td><td style=\"text-align: center;\"> 2003 </td><td style=\"text-align: center;\">    4.0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     1     </td></tr>\\n<tr><td style=\"text-align: center;\">    8798    </td><td style=\"text-align: center;\"> 2004 </td><td style=\"text-align: center;\">    3.8     </td><td style=\"text-align: center;\">    1    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\\n<tr><td style=\"text-align: center;\">    8798    </td><td style=\"text-align: center;\"> 2004 </td><td style=\"text-align: center;\">    3.8     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0      </td><td style=\"text-align: center;\">     0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">   1   </td><td style=\"text-align: center;\">      0       </td><td style=\"text-align: center;\">   0   </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0     </td><td style=\"text-align: center;\">    0    </td><td style=\"text-align: center;\">     0     </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pprint_train(item_train, item_features, ivs, i_s, maxcount=5, user=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Tower Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "from einops import rearrange\n",
    "\n",
    "\n",
    "# class CrossMultiHeadAttention(MultiHeadAttention):\n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         \"\"\"\n",
    "#         See MultiHeadAttention.\n",
    "#         Takes a cross hidden as query. Needs to be same dimension!\n",
    "#         \"\"\"\n",
    "#         super().__init__(*args, **kwargs)\n",
    "\n",
    "#         self.to_qkv = torch.nn.Linear(self.dim_input, self.dim_head * self.nr_heads * 2, bias=False)\n",
    "#         self.to_q = torch.nn.Linear(self.dim_input, self.dim_head * self.nr_heads, bias=False)\n",
    "\n",
    "#     def forward(self, x: torch.Tensor, cross_hidden: torch.Tensor, attn_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "#         assert cross_hidden.shape[-1] == x.shape[-1], \"Input and cross input require same embedding dimension!\"\n",
    "\n",
    "#         h = self.nr_heads\n",
    "#         k, v = self.to_qkv(x).chunk(2, dim=-1)\n",
    "#         q = self.to_q(cross_hidden)\n",
    "#         q, k, v = map(lambda t: rearrange(t, \"b n (h d) -> b h n d\", h=h), (q, k, v))\n",
    "#         sim = torch.einsum(\"b h i d, b h j d -> b h i j\", q, k) * self.scale\n",
    "\n",
    "#         if attn_mask is not None:\n",
    "#             attn_mask = attn_mask.unsqueeze(1)  # Add an extra dimension for the heads (b, 1, i, j)\n",
    "#             sim = sim.masked_fill(attn_mask == 0, float(\"-inf\"))\n",
    "\n",
    "#         attn = sim.softmax(dim=-1)\n",
    "#         attn = self.dropout(attn)\n",
    "\n",
    "#         out = torch.einsum(\"b h i j, b h j d -> b h i d\", attn, v)\n",
    "#         out = rearrange(out, \"b h n d -> b n (h d)\", h=h)\n",
    "        \n",
    "#         return self.to_out(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_input: int,\n",
    "        nr_heads: int = 8,\n",
    "        dropout_p: float = 0.0,\n",
    "        scale_factor: float = 0.5,\n",
    "    ):\n",
    "        \"\"\"Ye olde Multihead Attention, implmented with Einstein Notation.\n",
    "        Note: There' ain't no masking here, so be careful!\n",
    "\n",
    "        Args:\n",
    "            dim_input (int): The input dimension\n",
    "            nr_heads (int, optional): Number of heads. Defaults to 8.\n",
    "            dropout_p (float, optional): Dropout. Defaults to 0.0.\n",
    "            scale_factor (float, optional): Exponent of the scaling division - default is square root. Defaults to 0.5.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.nr_heads = nr_heads\n",
    "        self.dim_input = dim_input\n",
    "        self.dim_head = dim_input // nr_heads\n",
    "        self.scale = self.dim_head**-scale_factor\n",
    "\n",
    "        self.to_qkv = torch.nn.Linear(dim_input, self.dim_head * self.nr_heads * 3, bias=False)\n",
    "\n",
    "        self.to_out = torch.nn.Linear(self.dim_head * nr_heads, dim_input)\n",
    "        self.dropout = torch.nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, attn_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        h = self.nr_heads\n",
    "        q, k, v = self.to_qkv(x).chunk(3, dim=-1)\n",
    "        q, k, v = map(lambda t: rearrange(t, \"b n (h d) -> b h n d\", h=h), (q, k, v))\n",
    "        sim = torch.einsum(\"b h i d, b h j d -> b h i j\", q, k) * self.scale\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            attn_mask = attn_mask.unsqueeze(1)  # Add an extra dimension for the heads (b, 1, i, j)\n",
    "            sim = sim.masked_fill(attn_mask == 0, float(\"-inf\"))\n",
    "\n",
    "        attn = sim.softmax(dim=-1)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = torch.einsum(\"b h i j, b h j d -> b h i d\", attn, v)\n",
    "        out = rearrange(out, \"b h n d -> b n (h d)\", h=h)\n",
    "        return self.to_out(out)\n",
    "\n",
    "\n",
    "class UserTower(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, output_dim, nr_heads):\n",
    "        super(UserTower, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        # Input Embedding Layer (projects 4D input to embed_dim)\n",
    "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
    "        # Multi-Head Attention Layer\n",
    "        self.attention = MultiHeadAttention(dim_input=embed_dim, nr_heads=nr_heads)\n",
    "        # Fully Connected Layer (maps back to scalar output)\n",
    "        self.fc = nn.Linear(embed_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        x = self.embedding(x)  # Project to higher dimension\n",
    "        x = x.unsqueeze(1)  # Add sequence dimension: (batch, seq_len=1, embed_dim)\n",
    "        attn_output = self.attention(x, x)   \n",
    "        x = attn_output.mean(dim=1)  # Average over sequence dimension\n",
    "        return self.fc(x) \n",
    "\n",
    "class ProductTower(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, output_dim, nr_heads):\n",
    "        super(ProductTower, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        # Input Embedding Layer (projects 4D input to embed_dim)\n",
    "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
    "        # Multi-Head Attention Layer\n",
    "        self.attention = MultiHeadAttention(dim_input=embed_dim, nr_heads=nr_heads)\n",
    "        # Fully Connected Layer (maps back to scalar output)\n",
    "        self.fc = nn.Linear(embed_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        x = self.embedding(x)  # Project to higher dimension\n",
    "        x = x.unsqueeze(1)  # Add sequence dimension: (batch, seq_len=1, embed_dim)\n",
    "        attn_output = self.attention(x, x)   \n",
    "        x = attn_output.mean(dim=1)  # Average over sequence dimension\n",
    "        return self.fc(x) \n",
    "\n",
    "\n",
    "class UserTower_MLP(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, output_dim, nr_heads):\n",
    "        super(UserTower_MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, embed_dim)\n",
    "        self.fc2 = nn.Linear(embed_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "class ProductTower_MLP(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, output_dim):\n",
    "        super(ProductTower_MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, embed_dim)\n",
    "        self.fc2 = nn.Linear(embed_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "class TwoTowerRecommendationModel(pl.LightningModule):\n",
    "    def __init__(self, user_config, product_config, learning_rate):\n",
    "        super(TwoTowerRecommendationModel, self).__init__()\n",
    "        self.user_tower = UserTower(**user_config)\n",
    "        self.product_tower = ProductTower(**product_config)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, user_input, product_input):\n",
    "        \n",
    "        product_output = self.product_tower(product_input)\n",
    "        user_output = self.user_tower(user_input)\n",
    "        rating_pred_tensor = F.cosine_similarity(user_output, product_output)\n",
    "        return rating_pred_tensor\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        user_input, product_input, target = batch\n",
    "        rating_pred_tensor = self(user_input, product_input)\n",
    "        loss = self.criterion(rating_pred_tensor, target)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        user_input, product_input, target = batch\n",
    "        rating_pred_tensor = self(user_input, product_input)\n",
    "        loss = self.criterion(rating_pred_tensor, target)\n",
    "        self.log('val_loss', loss)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        user_input, product_input, target = batch\n",
    "        rating_pred_tensor = self(user_input, product_input)\n",
    "        loss = self.criterion(rating_pred_tensor, target)\n",
    "        self.log('test_loss', loss)\n",
    "        return {'preds': rating_pred_tensor, 'target': target}\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        user_input, product_input, _ = batch\n",
    "        rating_pred_tensor = self(user_input, product_input)\n",
    "        return rating_pred_tensor\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "# Generate Random Sample Data\n",
    "def generate_random_sample_data(num_samples: int):\n",
    "    \"\"\"This function generates random sample data for the two-tower model.\n",
    "    The idea is to understand how to structure the data for the model.\n",
    "\n",
    "    Args:\n",
    "        num_samples (int): number of samples\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    user_input_dim = 6\n",
    "    product_input_dim = 3\n",
    "    user_data = np.random.rand(num_samples, user_input_dim)\n",
    "    product_data = np.random.rand(num_samples, product_input_dim)\n",
    "    target_data = np.random.randint(0, 2, size=(num_samples, 1))  # Binary targets for F1 score\n",
    "\n",
    "    user_tensor = torch.tensor(user_data, dtype=torch.float32)\n",
    "    product_tensor = torch.tensor(product_data, dtype=torch.float32)\n",
    "    target_tensor = torch.tensor(target_data, dtype=torch.float32)\n",
    "\n",
    "    return user_tensor, product_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_synthetic_data = False\n",
    "if use_synthetic_data:\n",
    "    # Generate synthetic data\n",
    "    num_samples = 1000\n",
    "    user_data, product_data, target_data = generate_random_sample_data(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the shape of the data from movie lens dataset\n",
    "#user_data.shape, product_data.shape, target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# scale training data\n",
    "scaledata = True\n",
    "if scaledata:\n",
    "    item_train_save = item_train\n",
    "    user_train_save = user_train\n",
    "    y_train_save = y_train\n",
    "\n",
    "    scalerItem = StandardScaler()\n",
    "    scalerItem.fit(item_train)\n",
    "    item_train = scalerItem.transform(item_train)\n",
    "\n",
    "    scalerUser = StandardScaler()\n",
    "    scalerUser.fit(user_train)\n",
    "    user_train = scalerUser.transform(user_train)\n",
    "    \n",
    "    targetScaler = MinMaxScaler((-1, 1))\n",
    "    targetScaler.fit(y_train.reshape(-1, 1))\n",
    "    y_train = targetScaler.transform(y_train.reshape(-1, 1))\n",
    "\n",
    "    print(np.allclose(item_train_save, scalerItem.inverse_transform(item_train)))\n",
    "    print(np.allclose(user_train_save, scalerUser.inverse_transform(user_train)))\n",
    "\n",
    "user_data_tensor = torch.tensor(user_train[:, u_s:], dtype=torch.float32)\n",
    "product_data_tensor = torch.tensor(item_train[:, i_s:], dtype=torch.float32)\n",
    "target_data_tensor = torch.tensor(y_train.reshape(-1,1), dtype=torch.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.), tensor(-1.))"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data_tensor.max(), target_data_tensor.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([58187, 14]), torch.Size([58187, 16]), torch.Size([58187, 1]))"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data_tensor.shape, product_data_tensor.shape, target_data_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([58187, 14])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name          | Type         | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | user_tower    | UserTower    | 75.8 K | train\n",
      "1 | product_tower | ProductTower | 10.4 K | train\n",
      "2 | criterion     | MSELoss      | 0      | train\n",
      "-------------------------------------------------------\n",
      "86.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "86.3 K    Total params\n",
      "0.345     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JOHTORR/Repos/two_tower_model/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=13` in the `DataLoader` to improve performance.\n",
      "/Users/JOHTORR/Repos/two_tower_model/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/JOHTORR/Repos/two_tower_model/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=13` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1455/1455 [00:10<00:00, 142.06it/s, v_num=27]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JOHTORR/Repos/two_tower_model/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([21, 1])) that is different to the input size (torch.Size([21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 25/1455 [00:00<00:10, 138.55it/s, v_num=27]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JOHTORR/Repos/two_tower_model/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([22, 1])) that is different to the input size (torch.Size([22])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1455/1455 [00:10<00:00, 133.01it/s, v_num=27]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1455/1455 [00:10<00:00, 132.88it/s, v_num=27]\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "learning_rate = 0.001\n",
    "use_gpu = True\n",
    "\n",
    "# Model configurations\n",
    "user_config = {'input_dim': user_data_tensor.shape[1], \n",
    "               'embed_dim': 128,\n",
    "               'output_dim': 64, \n",
    "               'nr_heads': 8}\n",
    "product_config = {'input_dim': product_data_tensor.shape[1], \n",
    "                  'embed_dim': 128, \n",
    "                  'output_dim': 64,\n",
    "                  'nr_heads': 8}\n",
    "\n",
    "# Create DataLoader\n",
    "dataset = TensorDataset(user_data_tensor, product_data_tensor, target_data_tensor)\n",
    "num_samples = target_data_tensor.shape[0]\n",
    "train_size = int(0.8 * num_samples)\n",
    "test_size = num_samples - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Initialize model\n",
    "model = TwoTowerRecommendationModel(user_config, product_config, learning_rate)\n",
    "\n",
    "if not use_gpu:\n",
    "\n",
    "    # Train the model\n",
    "    trainer = pl.Trainer(max_epochs=epochs)\n",
    "    trainer.fit(model, train_loader, test_loader)\n",
    "\n",
    "else:\n",
    "    # Move model to GPU if available\n",
    "    device = torch.device('mps' if torch.cuda.is_available() else 'mps')\n",
    "    model.to(device)\n",
    "\n",
    "    # Train the model on GPU\n",
    "    trainer = pl.Trainer(max_epochs=epochs, accelerator=\"gpu\", devices=1)\n",
    "    trainer.fit(model, train_loader, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions for a new user\n",
    "First, we'll create a new user and have the model suggest movies for that user. After you have tried this example on the example user content, feel free to change the user content to match your own preferences and see what the model suggests. Note that ratings are between 0.5 and 5.0, inclusive, in half-step increments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_id = 5000\n",
    "new_rating_ave = 1.0\n",
    "new_action = 1.0\n",
    "new_adventure = 1\n",
    "new_animation = 1\n",
    "new_childrens = 1\n",
    "new_comedy = 5\n",
    "new_crime = 1\n",
    "new_documentary = 1\n",
    "new_drama = 1\n",
    "new_fantasy = 1\n",
    "new_horror = 1\n",
    "new_mystery = 1\n",
    "new_romance = 5\n",
    "new_scifi = 5\n",
    "new_thriller = 1\n",
    "new_rating_count = 3\n",
    "\n",
    "user_vec = np.array([[new_user_id, new_rating_count, new_rating_ave,\n",
    "                      new_action, new_adventure, new_animation, new_childrens,\n",
    "                      new_comedy, new_crime, new_documentary,\n",
    "                      new_drama, new_fantasy, new_horror, new_mystery,\n",
    "                      new_romance, new_scifi, new_thriller]])\n",
    "\n",
    "user_vecs = gen_user_vecs(user_vec,len(item_vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1883, 17), (1883, 17))"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_vecs.shape, item_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scaledata:\n",
    "    scaled_user_vecs = scalerUser.transform(user_vecs)\n",
    "    scaled_item_vecs = scalerItem.transform(item_vecs)\n",
    "    user_data_tensor = torch.tensor(scaled_user_vecs[:, u_s:], dtype=torch.float32)\n",
    "    product_data_tensor = torch.tensor(scaled_item_vecs[:, i_s:], dtype=torch.float32)\n",
    "    y_p = model(user_data_tensor, product_data_tensor).detach().numpy()\n",
    "    y_p = targetScaler.inverse_transform(y_p.reshape(-1, 1))\n",
    "else:\n",
    "    y_p = model(user_vecs[:, u_s:], item_vecs[:, i_s:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Vector Shape (1883, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction Vector Shape\", y_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.any(y_p < 0) : \n",
    "    print(\"Error, expected all positive predictions\")\n",
    "sorted_index = np.argsort(-y_p,axis=0).reshape(-1).tolist()  #negate to get largest rating first\n",
    "sorted_ypu   = y_p[sorted_index]\n",
    "sorted_items = item_vecs[sorted_index]\n",
    "sorted_user  = user_vecs[sorted_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p, user, item, movie_dict = sorted_ypu, sorted_user, sorted_items, movie_dict\n",
    "\n",
    "maxcount=10\n",
    "count = 0\n",
    "movies_listed = defaultdict(int)\n",
    "disp = [[\"y_p\", \"movie id\", \"rating ave\", \"title\", \"genres\"]]\n",
    "\n",
    "for i in range(0, y_p.shape[0]):\n",
    "    if count == maxcount:\n",
    "        break\n",
    "    count += 1\n",
    "    movie_id = item[i, 0].astype(int)\n",
    "    if movie_id in movies_listed:\n",
    "        continue\n",
    "    movies_listed[movie_id] = 1\n",
    "    disp.append([y_p[i, 0], item[i, 0].astype(int), item[i, 2].astype(float),\n",
    "                movie_dict[movie_id]['title'], movie_dict[movie_id]['genres']])\n",
    "\n",
    "table = tabulate.tabulate(disp, tablefmt='html',headers=\"firstrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">     y_p</th><th style=\"text-align: right;\">  movie id</th><th style=\"text-align: right;\">  rating ave</th><th>title                                                                                   </th><th>genres                               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">0.402865</td><td style=\"text-align: right;\">     55721</td><td style=\"text-align: right;\">     4.3    </td><td>Elite Squad (Tropa de Elite) (2007)                                                     </td><td>Action|Crime|Drama|Thriller          </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.402864</td><td style=\"text-align: right;\">     96829</td><td style=\"text-align: right;\">     4.3    </td><td>Hunt, The (Jagten) (2012)                                                               </td><td>Drama                                </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.402864</td><td style=\"text-align: right;\">      8014</td><td style=\"text-align: right;\">     4.25   </td><td>Spring, Summer, Fall, Winter... and Spring (Bom yeoreum gaeul gyeoul geurigo bom) (2003)</td><td>Drama                                </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.402863</td><td style=\"text-align: right;\">     48516</td><td style=\"text-align: right;\">     4.25234</td><td>Departed, The (2006)                                                                    </td><td>Crime|Drama|Thriller                 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.402862</td><td style=\"text-align: right;\">    116897</td><td style=\"text-align: right;\">     4.25   </td><td>Wild Tales (2014)                                                                       </td><td>Comedy|Drama|Thriller                </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.402861</td><td style=\"text-align: right;\">     71899</td><td style=\"text-align: right;\">     4.2    </td><td>Mary and Max (2009)                                                                     </td><td>Animation|Comedy|Drama               </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.40286 </td><td style=\"text-align: right;\">     55442</td><td style=\"text-align: right;\">     4.18182</td><td>Persepolis (2007)                                                                       </td><td>Animation|Drama                      </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.40286 </td><td style=\"text-align: right;\">      7361</td><td style=\"text-align: right;\">     4.16031</td><td>Eternal Sunshine of the Spotless Mind (2004)                                            </td><td>Drama|Romance|Sci-Fi                 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.40286 </td><td style=\"text-align: right;\">      6016</td><td style=\"text-align: right;\">     4.14667</td><td>City of God (Cidade de Deus) (2002)                                                     </td><td>Action|Adventure|Crime|Drama|Thriller</td></tr>\n",
       "<tr><td style=\"text-align: right;\">0.402859</td><td style=\"text-align: right;\">     57669</td><td style=\"text-align: right;\">     4.15854</td><td>In Bruges (2008)                                                                        </td><td>Comedy|Crime|Drama|Thriller          </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th style=\"text-align: right;\">     y_p</th><th style=\"text-align: right;\">  movie id</th><th style=\"text-align: right;\">  rating ave</th><th>title                                                                                   </th><th>genres                               </th></tr>\\n</thead>\\n<tbody>\\n<tr><td style=\"text-align: right;\">0.402865</td><td style=\"text-align: right;\">     55721</td><td style=\"text-align: right;\">     4.3    </td><td>Elite Squad (Tropa de Elite) (2007)                                                     </td><td>Action|Crime|Drama|Thriller          </td></tr>\\n<tr><td style=\"text-align: right;\">0.402864</td><td style=\"text-align: right;\">     96829</td><td style=\"text-align: right;\">     4.3    </td><td>Hunt, The (Jagten) (2012)                                                               </td><td>Drama                                </td></tr>\\n<tr><td style=\"text-align: right;\">0.402864</td><td style=\"text-align: right;\">      8014</td><td style=\"text-align: right;\">     4.25   </td><td>Spring, Summer, Fall, Winter... and Spring (Bom yeoreum gaeul gyeoul geurigo bom) (2003)</td><td>Drama                                </td></tr>\\n<tr><td style=\"text-align: right;\">0.402863</td><td style=\"text-align: right;\">     48516</td><td style=\"text-align: right;\">     4.25234</td><td>Departed, The (2006)                                                                    </td><td>Crime|Drama|Thriller                 </td></tr>\\n<tr><td style=\"text-align: right;\">0.402862</td><td style=\"text-align: right;\">    116897</td><td style=\"text-align: right;\">     4.25   </td><td>Wild Tales (2014)                                                                       </td><td>Comedy|Drama|Thriller                </td></tr>\\n<tr><td style=\"text-align: right;\">0.402861</td><td style=\"text-align: right;\">     71899</td><td style=\"text-align: right;\">     4.2    </td><td>Mary and Max (2009)                                                                     </td><td>Animation|Comedy|Drama               </td></tr>\\n<tr><td style=\"text-align: right;\">0.40286 </td><td style=\"text-align: right;\">     55442</td><td style=\"text-align: right;\">     4.18182</td><td>Persepolis (2007)                                                                       </td><td>Animation|Drama                      </td></tr>\\n<tr><td style=\"text-align: right;\">0.40286 </td><td style=\"text-align: right;\">      7361</td><td style=\"text-align: right;\">     4.16031</td><td>Eternal Sunshine of the Spotless Mind (2004)                                            </td><td>Drama|Romance|Sci-Fi                 </td></tr>\\n<tr><td style=\"text-align: right;\">0.40286 </td><td style=\"text-align: right;\">      6016</td><td style=\"text-align: right;\">     4.14667</td><td>City of God (Cidade de Deus) (2002)                                                     </td><td>Action|Adventure|Crime|Drama|Thriller</td></tr>\\n<tr><td style=\"text-align: right;\">0.402859</td><td style=\"text-align: right;\">     57669</td><td style=\"text-align: right;\">     4.15854</td><td>In Bruges (2008)                                                                        </td><td>Comedy|Crime|Drama|Thriller          </td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
